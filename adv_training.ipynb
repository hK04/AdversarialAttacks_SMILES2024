{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ce6acdd-1cdd-413b-a728-dc00d3f13038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "dir2 = os.path.abspath('')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if dir1 not in sys.path:\n",
    "    sys.path.append(dir1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "100da776-012f-455e-b5a6-3b8d8fc92ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import hydra\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from src.utils import fix_seed, save_config, save_compiled_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fe86fca-6837-42b8-8d1f-e29e37fd1077",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA extension for structured kernels (Cauchy and Vandermonde multiplication) not found. Install by going to extensions/kernels/ and running `python setup.py install`, for improved speed and memory efficiency. Note that the kernel changed for state-spaces 4.0 and must be recompiled.\n",
      "Falling back on slow Cauchy and Vandermonde kernel. Install at least one of pykeops or the CUDA extension for better speed and memory efficiency.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from src.config import get_attack, get_criterion, get_disc_list, get_model\n",
    "from src.data import MyDataset, load_data, transform_data\n",
    "from src.estimation.estimators import AttackEstimator\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from src.data import MyDataset, load_data, transform_data\n",
    "from src.training.train import Trainer\n",
    "from src.utils import fix_seed, save_config, save_compiled_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44901300-07f0-442e-8b9d-b05034d54707",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e2d5e02-8c92-4858-b122-379473eb4569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(cfg, train_loader, test_loader):\n",
    "    augmentator = (\n",
    "        [instantiate(trans) for trans in cfg[\"transform_data\"]] if cfg[\"transform_data\"]\n",
    "        else None\n",
    "    )\n",
    "    \n",
    "    logger = SummaryWriter(cfg[\"save_path\"] + \"/tensorboard\")\n",
    "    fix_seed(cfg['model_id_attack'])\n",
    "\n",
    "    const_params = {\n",
    "        \"logger\": logger,\n",
    "        \"print_every\": 10, #cfg[\"print_every\"],\n",
    "        \"device\": device,\n",
    "        \"seed\": cfg['model_id_attack'],\n",
    "        \"train_self_supervised\": False\n",
    "    }\n",
    "\n",
    "    trainer_params = dict(cfg[\"training_params\"])\n",
    "    trainer_params.update(const_params)\n",
    "    trainer = Trainer.initialize_with_params(**trainer_params)\n",
    "\n",
    "    trainer.train_model(train_loader, test_loader)\n",
    "    logger.close()\n",
    "    \n",
    "    return trainer.model\n",
    "\n",
    "\n",
    "def get_attacks(cfg, eps, n_steps_list, model):\n",
    "    attack_model = model\n",
    "\n",
    "    criterion = get_criterion(cfg[\"criterion_name\"], cfg[\"criterion_params\"])\n",
    "    \n",
    "    disc_check_list = None\n",
    "    \n",
    "    estimator = AttackEstimator(\n",
    "        disc_check_list,\n",
    "        cfg[\"metric_effect\"],\n",
    "        cfg[\"metric_hid\"],\n",
    "        batch_size=cfg[\"estimator_batch_size\"],\n",
    "    )\n",
    "    \n",
    "    attacks = list()\n",
    "    \n",
    "    for n_steps in n_steps_list:\n",
    "        attack_params = dict(cfg[\"attack\"][\"attack_params\"])\n",
    "        attack_params[\"model\"] = attack_model\n",
    "        attack_params[\"criterion\"] = criterion\n",
    "        attack_params[\"estimator\"] = estimator\n",
    "        attack_params[\"alpha\"] = 0\n",
    "        attack_params[\"eps\"] = eps\n",
    "        attack_params[\"n_steps\"] = n_steps\n",
    "    \n",
    "        attacks.append(get_attack(cfg[\"attack\"][\"name\"], attack_params))\n",
    "\n",
    "    return attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c9ac41-359b-43e0-9b20-c4c33acee380",
   "metadata": {},
   "source": [
    "# Config + data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbd1e2a1-f28c-4e2e-ad6e-a514f770b658",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize(config_path='config/my_configs', version_base=None)\n",
    "cfg = compose(config_name='mix_exp.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bc87da8-b81b-4da0-a7a6-bdbc319d2cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset PowerCons\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset\", cfg[\"dataset\"]['name'])\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_data(cfg[\"dataset\"]['name'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = transform_data(\n",
    "    X_train, \n",
    "    X_test, \n",
    "    y_train, \n",
    "    y_test, \n",
    "    slice_data=cfg[\"slice\"]\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    MyDataset(X_test, y_test), \n",
    "    batch_size=cfg[\"batch_size\"], \n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    MyDataset(X_train, y_train), \n",
    "    batch_size=cfg[\"batch_size\"], \n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169acd39-eed9-4217-a20f-be6a47888909",
   "metadata": {},
   "source": [
    "# Train original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7394fbd-16ed-4cdf-9d55-ad434334edbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train loss: 0.462; acc_train 0.844; test loss: 0.379; acc_test 0.856; f1_test 0.874; balance 0.644; certainty 0.734\n",
      "Epoch 11 train loss: 0.106; acc_train 0.972; test loss: 0.143; acc_test 0.978; f1_test 0.978; balance 0.522; certainty 0.892\n",
      "Epoch 21 train loss: 0.064; acc_train 0.978; test loss: 0.122; acc_test 0.961; f1_test 0.963; balance 0.539; certainty 0.913\n",
      "Epoch 31 train loss: 0.039; acc_train 1.0; test loss: 0.102; acc_test 0.972; f1_test 0.973; balance 0.528; certainty 0.933\n",
      "Epoch 41 train loss: 0.025; acc_train 1.0; test loss: 0.083; acc_test 0.972; f1_test 0.973; balance 0.528; certainty 0.947\n",
      "Epoch 51 train loss: 0.017; acc_train 1.0; test loss: 0.078; acc_test 0.978; f1_test 0.978; balance 0.522; certainty 0.954\n"
     ]
    }
   ],
   "source": [
    "model_orig = train(cfg, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c9bbf4-5ec8-4d8f-b016-c983ca1a462e",
   "metadata": {},
   "source": [
    "### Attack data with original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cb3a2fcd-ed2d-477a-b0c6-3a76325f16ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logging\n",
      "logging\n",
      "logging\n",
      "logging\n"
     ]
    }
   ],
   "source": [
    "n_steps_list = np.arange(5, 25, 5) ##### менять\n",
    "\n",
    "attacks = get_attacks(cfg, 0.005, n_steps_list, model_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5665369c-d3e5-439e-9a94-190c139585f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  9.38it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  9.42it/s]\n",
      "100%|██████████| 15/15 [00:01<00:00,  9.65it/s]\n",
      "100%|██████████| 20/20 [00:02<00:00,  9.53it/s]\n"
     ]
    }
   ],
   "source": [
    "attacked_train = {}\n",
    "\n",
    "for attack in attacks:\n",
    "    X_adv = attack.apply_attack(train_loader).squeeze()\n",
    "    attacked_train[attack.n_steps] = X_adv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c2f3bf-bb10-40cc-9c9f-638b566e51f0",
   "metadata": {},
   "source": [
    "### Mix attack data with train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "61f5087f-e9fe-4de9-9b02-30a8f5a5cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_loader.dataset.X\n",
    "y_train = train_loader.dataset.y\n",
    "\n",
    "X_train_mixed = torch.cat([X_train, attacked_train[5]]) ###### шаги атаки\n",
    "y_train_mixed = torch.cat([y_train, y_train])\n",
    "\n",
    "train_loader_mixed = DataLoader(\n",
    "    MyDataset(X_train_mixed, y_train_mixed), \n",
    "    batch_size=cfg[\"batch_size\"], \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea940680-b081-4574-8064-ce3f8dc385c2",
   "metadata": {},
   "source": [
    "# Train on mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "46dc1555-8b12-4e5d-bb00-56aa7dd70e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train loss: 0.401; acc_train 0.836; test loss: 0.303; acc_test 0.911; f1_test 0.918; balance 0.589; certainty 0.774\n",
      "Epoch 11 train loss: 0.078; acc_train 0.981; test loss: 0.122; acc_test 0.967; f1_test 0.968; balance 0.533; certainty 0.91\n",
      "Epoch 21 train loss: 0.035; acc_train 1.0; test loss: 0.078; acc_test 0.978; f1_test 0.978; balance 0.522; certainty 0.946\n",
      "Epoch 31 train loss: 0.013; acc_train 1.0; test loss: 0.056; acc_test 0.989; f1_test 0.989; balance 0.511; certainty 0.964\n",
      "Epoch 41 train loss: 0.006; acc_train 1.0; test loss: 0.052; acc_test 0.989; f1_test 0.989; balance 0.511; certainty 0.97\n",
      "Epoch 51 train loss: 0.004; acc_train 1.0; test loss: 0.05; acc_test 0.989; f1_test 0.989; balance 0.511; certainty 0.974\n"
     ]
    }
   ],
   "source": [
    "model_mixed = train(cfg, train_loader_mixed, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b107f87d-d05c-4187-9149-ca530a85a329",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "639e4e4f-34d0-4298-b019-8581de583fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logging\n",
      "logging\n",
      "logging\n",
      "logging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 12.24it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  9.47it/s]\n",
      "100%|██████████| 15/15 [00:01<00:00,  9.41it/s]\n",
      "100%|██████████| 20/20 [00:02<00:00,  9.45it/s]\n"
     ]
    }
   ],
   "source": [
    "attacks = get_attacks(cfg, 0.01, n_steps_list, model_mixed) # Атакуем градиентами новой модели\n",
    "# attacks = get_attacks(cfg, 0.01, n_steps_list, model_orig) # Атакуем градиентами оригинальной модели\n",
    "\n",
    "X_test = test_loader.dataset.X\n",
    "y_test = test_loader.dataset.y\n",
    "\n",
    "attacked_test = {}\n",
    "\n",
    "for attack in attacks:\n",
    "    X_adv = attack.apply_attack(test_loader).squeeze()\n",
    "    attacked_test[attack.n_steps] = X_adv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755ed4f0-b1f6-4e09-b79b-f1a73864ddef",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4a660054-c00a-4bd6-89f6-6f3c3fd43c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "977e96b2-bcd7-4bc1-9801-cf8e96939932",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "test_samples = attacked_test[20].unsqueeze(-1).to(device) ###### шаги атаки\n",
    "\n",
    "preds_orig = model_orig(test_samples) \n",
    "preds_mixed = model_mixed(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8a049972-8f7f-4c6d-926b-8e6a60d998c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7988770008087158 1.7478158473968506\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    criterion(preds_orig, y_test.float().to(device)).item(),\n",
    "    criterion(preds_mixed, y_test.float().to(device)).item()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "90203f67-ffe2-4535-b195-18e22feff1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7760493827160494"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, preds_orig.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "98fcd151-bd1a-45c1-a46c-a0598e73fa97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5375308641975308"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, preds_mixed.cpu().detach().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
